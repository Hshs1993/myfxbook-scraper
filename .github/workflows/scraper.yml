name: Myfxbook Scraper

on:
  schedule:
    - cron: '*/10 * * * *'  # Esegui ogni 10 minuti
  workflow_dispatch:  # Permette di avviare manualmente l'azione

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v2

      - name: Set up Python
        uses: actions/setup-python@v3
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          pip install selenium
      - name: Download Latest ChromeDriver
        run: |
          sudo apt update
          sudo apt install -y wget unzip curl jq
          CHROME_VERSION=$(google-chrome --version | awk '{print $3}' | cut -d'.' -f1)
          DRIVER_VERSION=$(curl -s "https://googlechromelabs.github.io/chrome-for-testing/LATEST_RELEASE_$CHROME_VERSION")
          DRIVER_URL="https://storage.googleapis.com/chrome-for-testing-public/$CHROME_VERSION.0.0/chromedriver-linux64.zip"
          echo "Scaricando ChromeDriver versione $DRIVER_VERSION"
          wget "$DRIVER_URL" -O chromedriver-linux64.zip || { echo "‚ùå ERRORE: ChromeDriver non trovato!"; exit 1; }
          unzip chromedriver-linux64.zip
          sudo mv chromedriver-linux64/chromedriver /usr/local/bin/
          chmod +x /usr/local/bin/chromedriver




      - name: Run scraper
        run: python scraper.py
      - name: Commit and Push CSV
        run: |
          git config --global user.name "github-actions"
          git config --global user.email "github-actions@github.com"
          git add myfxbook_data.csv
          git commit -m "Aggiornamento dati Myfxbook"
          git push
