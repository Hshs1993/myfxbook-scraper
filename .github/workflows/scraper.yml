name: Myfxbook Scraper

on:
  schedule:
    - cron: '*/10 * * * *'  # Esegui ogni 10 minuti
  workflow_dispatch:  # Permette di avviare manualmente l'azione

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v2

      - name: Set up Python
        uses: actions/setup-python@v3
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          pip install selenium
      - name: Check Chrome Version
        run: google-chrome --version

      - name: Download ChromeDriver
        run: |
          sudo apt update
          sudo apt install -y wget unzip
          CHROME_VERSION=$(google-chrome --version | awk '{print $3}' | cut -d'.' -f1)
          DRIVER_URL=$(curl -s "https://googlechromelabs.github.io/chrome-for-testing/latest-patch-versions-per-build-with-downloads.json" | jq -r ".builds[\"$CHROME_VERSION\"].downloads.chromeDriver[] | select(.platform == \"linux64\").url")
          wget "$DRIVER_URL" -O chromedriver-linux64.zip
          unzip chromedriver-linux64.zip
          sudo mv chromedriver-linux64/chromedriver /usr/local/bin/
          chmod +x /usr/local/bin/chromedriver

      - name: Run scraper
        run: python scraper.py
      - name: Commit and Push CSV
        run: |
          git config --global user.name "github-actions"
          git config --global user.email "github-actions@github.com"
          git add myfxbook_data.csv
          git commit -m "Aggiornamento dati Myfxbook"
          git push
